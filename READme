# STEDI Human Balance Analytics - Data Lakehouse Project

This project is part of the Udacity Data Engineering Nanodegree. It simulates a real-world scenario for building a data lakehouse architecture on AWS to process human balance data collected from mobile devices and IoT sensors. The goal is to curate clean, trusted, and machine-learning-ready data for analytics and predictive modeling.

---

## ğŸ§  Project Objective

To ingest, transform, and curate sensor and user data related to human balance using AWS-native tools. The curated data is intended for use in training machine learning models that can assess a userâ€™s balance stability and detect anomalies in sensor readings.

---

## ğŸ“Š Data Sources

The data is split into three **landing zone datasets** stored in S3:

- `customer_landing/`: Personal and consent information about users.
- `accelerometer_landing/`: Time-series data from accelerometer sensors.
- `step_trainer_landing/`: Step trainer device readings with timestamps.

---

## ğŸ” Data Pipeline Architecture

This project follows a **three-zone data lake architecture**:

### 1. Landing Zone
Raw JSON files from S3 are registered as external tables using SQL DDL scripts. These are defined manually using Athena:

- `customer_landing`
- `accelerometer_landing`
- `step_trainer_landing`

ğŸ“„ Files:
- `customer_landing.sql`
- `accelerometer_landing.sql`
- `step_trainer_landing.sql`

---

### 2. Trusted Zone
Each dataset is cleaned and transformed to remove untrusted or irrelevant records using AWS Glue Studio Visual Jobs:

- `customer_landing_to_trusted.py`: Filters out customers who didnâ€™t give research consent.
- `accelerometer_landing_to_trusted.py`: Joins accelerometer data with trusted customer records.
- `step_trainer_landing_to_trusted.py`: Promotes raw step trainer data to trusted zone.

ğŸ“„ Files:
- `customer_landing_to_trusted.py`
- `accelerometer_landing_to_trusted.py`
- `step_trainer_trusted.py`

---

### 3. Curated Zone
The trusted datasets are joined to form a machine learningâ€“ready dataset:

- `customer_trusted_to_curated.py`: Joins step trainer data with trusted customers by `serialNumber`.
- `machine_learning_curated.py`: Joins `step_trainer_trusted` with `accelerometer_trusted` on `sensorreadingtime = timestamp`.

ğŸ“„ Files:
- `customer_trusted_to_curated.py`
- `machine_learning_curated.py`

The final curated dataset contains over **43,000 rows** of clean sensor data ready for training machine learning models.

---

## ğŸ§ª Technologies & Tools Used

This project involved a combination of infrastructure automation, AWS services, visual ETL tools, and programming/scripting:

### ğŸ› ï¸ Infrastructure & Orchestration
- **Terraform**: Provisioned S3 buckets, IAM roles, and Glue resources programmatically
- **AWS CLI**: Used to upload landing datasets to S3 and manage resources via command line

### â˜ï¸ AWS Services
- **Amazon S3**: Data lake storage (landing, trusted, curated zones)
- **AWS Glue Studio**: Visual ETL jobs using PySpark (SQL & transformations)
- **AWS Glue Data Catalog**: Schema definitions and metadata management
- **AWS Glue Jobs**: Auto-generated PySpark ETL scripts with configurable steps
- **AWS Athena**: SQL query engine used for validation and DDL operations

### ğŸ Programming & Query Languages
- **SQL**: For schema creation, filtering, and joins (Athena & Glue Studio)
- **Python (PySpark)**: Auto-generated by Glue Studio (included in `.py` Glue Job scripts)
- **JSON**: Input format for all landing zone data

### ğŸ§° Developer Tools
- **Visual Studio Code**: Local editing and organization of `.sql` and `.py` scripts
- **Markdown**: For documentation and project notes (`README.md`)

---

## ğŸ“· Screenshots Included

| Screenshot File | Description |
|-----------------|-------------|
| `customer_landing.png` | Row count from Athena |
| `accelerometer_landing.png` | Row count from Athena |
| `step_trainer_landing.png` | Row count from Athena |
| `customer_trusted.png` | Filtered trusted customers |
| `accelerometer_trusted.png` | Joined accelerometer data |
| `step_trainer_trusted.png` | Step trainer records |
| `customers_curated.png` | Joined customer + device data |
| `machine_learning_curated.png` | Final dataset used for ML |

---

## ğŸ“ Files Delivered

### SQL DDL Scripts
- `customer_landing.sql`
- `accelerometer_landing.sql`
- `step_trainer_landing.sql`

### Glue Job Scripts
- `customer_landing_to_trusted.py`
- `accelerometer_landing_to_trusted.py`
- `step_trainer_trusted.py`
- `customer_trusted_to_curated.py`
- `machine_learning_curated.py`

### Athena Query Results (Screenshots)
- `*.png` screenshots for row count validation

---

## âœ… Final Outcome

The final `machine_learning_curated` table contains:
- âœ… ~43,681 clean records (after fixing row explosion caused by timestamp duplications)
- Ready for ML model ingestion and performance analytics

---

## ğŸ™Œ Acknowledgments

Thanks to Udacity for the challenging and realistic capstone, and to AWS for providing the tools and infrastructure that made building a production-grade data pipeline achievable.

<!-- 
aws s3 cp customer/ s3://stedi-datalake-terraform/customer_landing/ --recursive --profile kareem-profile
aws s3 cp accelerometer/ s3://stedi-datalake-terraform/accelerometer_landing/ --recursive --profile kareem-profile
aws s3 cp step_trainer/ s3://stedi-datalake-terraform/step_trainer_landing/ --recursive --profile kareem-profile

C:\Users\kimo_\Desktop\Udacity\Project 3\Project\nd027-Data-Engineering-Data-Lakes-AWS-Exercises\project\starter
 -->


